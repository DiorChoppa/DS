{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шпаргалка - `pandas`\n",
    "\n",
    "Это ключевая библиотека для работы с данными. Данная библиотека содержит очень большую функциональность и можно долго узнавать все ее возможности, но нашей задачей сейчас является - узнать наиболее важные функции, которые помогут дальше работать с данными.\n",
    "\n",
    "## Видео шаг по шагу (доп. поддержка для начинающих)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe style=\"height:500px;width:100%\" src=\"https://www.youtube.com/embed/Yug7QHkt0qU\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe style=\"height:500px;width:100%\" src=\"https://www.youtube.com/embed/Yug7QHkt0qU\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам для начала нужно вчитать (импортировать) сами библиотеки `pandas` и `numpy` (данная библиотека активно используется в самом `pandas`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека pandas была создана как эффективное представление данных в виде серии (анг. \"Series\") или таблицы данных (анг. \"DataFrame\"). \n",
    "\n",
    "## Series \n",
    "Давай создадим простую серию (или вектор), которая будет состоять из двух строчек. *Обрати внимание*, что каждая строка имеет индекс. В  случае первой строки - `row1` - это индекс, а `row1 value` - значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq = pd.Series({\n",
    "    'row1': 'row1 value', \n",
    "    'row2': 'row2 value'\n",
    "})\n",
    "sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Series` - это одноколоночные или векторные данные. У каждой серии есть значения и индексы. Мы можем использовать `.index` для доступа к индексам. Зачем нам индексы? Это введено с целью оптимизации. Для начала (если это звучит трудно), не нужно сильно в это вникать - просто запомни, что благодаря индексам эта вся структура работает быстрее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sq.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "Как упоминалось ранее, `Series` - это один столбец. Если мы хотим загрузить данные в виде «таблицы» (например, файла Excel), нам на помощь приходит `DataFrame`. Говоря простым языком, в терминологии `pandas` таблицу называют `DataFrame`.\n",
    "\n",
    "Создадим таблицу из трех столбцов и двух строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "     'column_a': {'row1': 'row1 col a', 'row2': 'row2 col a'}, \n",
    "     'column_b': {'row1': 'row1 col b', 'row2': 'row2 col b'}, \n",
    "     'column_c': {'row1': 'row1 col c', 'row2': 'row2 col c'}, \n",
    "    })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давай разберем DataFrame на простые элементы:\n",
    "\n",
    "![](../images/df.png)\n",
    "\n",
    "- **индекс** (зеленая зона) - грубо говоря - это номера строк (но там могут быть и не только номера)\n",
    "- **столбцы** (красная область) - названия наших столбцов\n",
    "- **значения** (синяя область) - содержимое таблицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Столбцы\n",
    "\n",
    "Предположим, мы хотим выбрать из всей таблицы второй столбец, название которого `column_b`. Это можно сделать легко следующим образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['column_b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом видим все значения (для всех строк) в столбце `column_b` и дополнительно еще видим индекс (`row1` и `row2` в данном случае).\n",
    "\n",
    "\n",
    "Используя `.columns` можно проверить, какие столбцы (их названия в виде списка) есть в` DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что в нашей таблице (анг. `DataFame`) три столбца: `['column_a', 'column_b', 'column_c']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если возникла необходимость переименовать столбцы, есть несколько способов сделать это. Довольно простой: нужно написать новым списком `df.columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['new_column1', 'new_column2', 'new_column3'] \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда возникает такая ситуация, что хотим переименовать только один столбец, это можно легко сделать вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'new_column1': 'abc'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давай разберем наиболее интересные функции, которые могут пригодиться. Немного упрощая можно поделить наиболее необходимые функции на 7 групп.\n",
    "\n",
    "### 1. Вчитать данные\n",
    "- `.read_hdf()`\n",
    "- `.read_csv()`\n",
    "\n",
    "### 2. Осмотр данных\n",
    "- `.sample`\n",
    "- `.head()`\n",
    "- `.sample()`\n",
    "- `.tail()`\n",
    "- `.info()`\n",
    "\n",
    "### 3. Трансформация/изменения данных\n",
    "- `.map()`\n",
    "- `.apply()`\n",
    "- `.fillna()`\n",
    "- `.factorize()`\n",
    "\n",
    "### 4. Сортировка и группировка данных\n",
    "- `.value_counts()`\n",
    "- `.groupby()`\n",
    "- `.agg()`\n",
    "- `.sort_values()`\n",
    "- `.pivot_table()`\n",
    "\n",
    "### 5. Статистические функции\n",
    "- `.mean()`\n",
    "- `.median()`\n",
    "- `.min()`\n",
    "- `.max()`\n",
    "\n",
    "### 6. Визуализация\n",
    "- `.hist()`\n",
    "\n",
    "\n",
    "### 7. Другие функции\n",
    "- `.qcut()` \n",
    "- `.unique()`\n",
    "- `.nunique()`\n",
    "\n",
    "\n",
    "Сейчас на конкретном примере проработаем все эти функции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь вчитываем данные. В нашем случае они записаны в формате - [hdf](https://en.wikipedia.org/wiki/Hierarchical_Data_Format), который иногда называют h5 (имеется ввиду hdf5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(\"../input/train_data.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы проверить сколько строк и колонок можно использовать `.shape` (кстати, обрати внимание, что `.shape` без скобочек)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается у нас **22 732** строчки и **8** столбцов.\n",
    "\n",
    "Если мы хотим посмотреть, например, первые 5 строк, используем `.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть 5 случайных строок, используя `.sample()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть 5 последних строчек, используя функцию `.tail()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При помощи функции `.info()` можно подсмотреть информацию о столбцах:\n",
    "- название столбца\n",
    "- тип данных (то как `pandas` распознал и это потом можно пробовать менять)\n",
    "- количество не пустых значений (анг. `non null`) для каждого столбца\n",
    "- количество памяти (нижняя граница), которую занимают эти данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Трансформация/изменение данных\n",
    "- `.map()`\n",
    "- `.apply()`\n",
    "- `.fillna()`\n",
    "- `.factorize()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с функнции `.map()`. Она часто появляется. Идея достаточно простая, у нас есть столбец с некоторыми значениями. Далее мы хотим пройти значение за значением и создать новое, на основании определенной логики.\n",
    "\n",
    "Лучше всего показать на примере. Давай посмотрим на значения в столбце `\"price\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что значениия написаны в рублях `₽`. Нам нужно из этих значений сделать числа.\n",
    "\n",
    "Было `5 402 084 ₽` (как строчка) и должно быть `5402084` (как число). Как это можно сделать? Нам нужно создать логику, которая со строчки вытянет число. Есть разные способы. Давай выберем простой. Для начала нам нужно избавиться от нечисловых знаков, например, `₽`. Для этого можно использовать функцию `.split()`. И она поделит нашу строчку на два компонента до `₽` и после. То, что \"до\"\" - это число."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"5 402 084 ₽\".split(\"₽\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"5 402 084 ₽\".split(\"₽\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь еще нужно удалить пробелы - для этого можно использовать `.replace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"5 402 084 ₽\".split(\"₽\")[0].replace(\" \", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обрати внимание, что это строка (об этом говорит `'` в начале и в конце). Теперь осталось только сконвертировать это значение в число (`int`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(\"5 402 084 ₽\".split(\"₽\")[0].replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот таким образом из оригинальной строки `\"5 402 084 ₽\"` мы получили число  `5402084`. Теперь еще осталось выполнить эту логика для всех значений в столбце `price`. И тут как раз нам поможет функция `.map()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"].map(lambda x: int(x.split(\"₽\")[0].replace(\" \", \"\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут еще появилась анонимная функция - `lambda`. Но можно сделать обычную функцию с именем и назвать ее, например, `.parse_price()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_price(x):\n",
    "    return int(x.split(\"₽\")[0].replace(\" \", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь можно это применить таким образом:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price\"].map(parse_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция `.apply()` - это более расширенная функция, чем `.map()`. И это дает возможность иметь доступ одновременно к нескольким столбцам. Но важно помнить про `axis=1`. Ниже пример."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.apply(lambda row: row[\"geo_block\"][0] + \" => \" + row[\"price\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Отсутствующие значения\n",
    "\n",
    "Есть разные стратегии, что делать с пустыми значениями. Весьма хороший подход использовать функцию `.fillna()`. Например, мы часто будем использовать простой трик, заменяя пустые значения числом -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Конвертация даных в числа\n",
    "\n",
    "Алгоритмы машинного обучения (которые будем использовать) \"ждут\" данные в виде чисел, т.е. строки, даты и другие форматы данных нужно как-то преобразовать в числовые. Существуют разные подходы - но опять же, простой и прагматичный подход - это использовать функцию `.factorize()`.\n",
    "\n",
    "\n",
    "Как это работает на деле?\n",
    "\n",
    "Лучше всего взять какой-нибдуь пример. Давай посмотрим на столбец `geo_block`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"geo_block\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь у нас список. Используя функцию `.map()`, можем, например, достать первое значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"geo_block\"].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давай \"закодируем\" каждому уникальному значению свой уникальный идентификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids, labels = df[\"geo_block\"].map(lambda x: x[0]).factorize()\n",
    "ids, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.factorize()` возвращает два значения - ID и этикетки (анг. `labels`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Что здесь получилось?\n",
    "- `'г. Москва'` получило `id=0`, иными словами, везде, где будет значение `'г. Москва'` оно заменится на 0.\n",
    "- `'Новая Москва'` получило `id=1`, т.е. везде где будет значение `'Новая Москва'` оно заменится на 1.\n",
    "- и т.д.\n",
    "\n",
    "Почему именно `'г. Москва'` получило значение 0,  а не 10? На самом деле это не так важно. Просто `.factorize()` работает таким образом, что поочередно обрабатывает все доступные id. Сразу 0, потом 1 и тд. Получается, что `'г. Москва'` попалась как первое значение - поэтому \"забрало\" себе 0. \n",
    "\n",
    "Очень часто `.factorize()[0]` т.е. вытягиваем только идентификаторы и приписываем результат в новую колонку, например `geo_block_0_cat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"geo_block_0_cat\"] = df[\"geo_block\"].map(lambda x: x[0]).factorize()[0]\n",
    "df[\"geo_block_0_cat\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видишь, `geo_block_0_cat` - это новый столбец, который содержит уникальные идентификаторы. Кстати, префикс `_cat` значит, что данный столбец создан при помощи `.factorize()`. Почему `_cat` 😻? Это сокращение от `categorical` (категориальные переменные)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Сортировка и группировка данных\n",
    "- `.value_counts()`\n",
    "- `.groupby()`\n",
    "- `.agg()`\n",
    "- `.sort_values()`\n",
    "- `.pivottable()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начнем с `.value_counts()`. Это очень удобнная функция. Возвращаясь к предыдущему примеру, можно подсмотреть, какие уникальные значения в первом блоке `geo_block`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"geo_block\"].map(lambda x: x[0]).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что \n",
    "- `г. Москва` появляется **19 310**\n",
    "- `Новая Москва` появляется **3 021**\n",
    "- `г. Зеленоград` появляется **210**\n",
    "\n",
    "\n",
    "Очень удобная функция, чтобы \"подсмотреть\" 👀 какие значения и сколько раз появляются. Значения можно преобразовать в проценты, чтобы понять например `г. Москва` - сколько раз появляется в процентном соотношении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"geo_block\"].map(lambda x: x[0]).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что `г. Москва` появляется в 84.94%, `Новая Москва` появляется 13.28% и тд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разберемся с:\n",
    "- `.groupby()`\n",
    "- `.agg()`\n",
    "- `.sort_values()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Только сразу нужно приготовить два новых столбца:\n",
    "- `price_num` - это числовое значение, поделенное на миллион (чтобы легче было интерпретировать)\n",
    "- `geo_block_0` - первое значение в geo_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price_num\"] = df[\"price\"].map(parse_price).map(lambda x: x/1000000)\n",
    "df[\"geo_block_0\"] = df[\"geo_block\"].map(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь давай сгруппируем `geo_block_0` по ключу и потом найдем, например, среднее значение по цене. Иными словами можно посмотреть, какая средняя цена в `г. Москва`, `Новая Москва` и тд."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[ [\"geo_block_0\", \"price_num\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"geo_block_0\").agg(\"mean\")[\"price_num\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, например, что средняя цена за недвижимость в `Новая Москва` - 7.27 млн. рублей, в `г. Москва` 19.29 млн. рублей. А, например, в п. Рублево средняя стоимость недвижимости 30 млн. рублей.\n",
    "\n",
    "\n",
    "Немного неудобно смотреть данные, когда они не отсортированы, а для этого можно использовать `sort_values()`. По умолчанию сортируются данные по возрастанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"geo_block_0\").agg(\"mean\")[\"price_num\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно поменять порядок сортироовки и сделать по убыванию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"geo_block_0\").agg(\"mean\")[\"price_num\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь очень хорошо видно (в данных, к которым у нас есть доступ - это не целая картина!) - самая дорогая недвижимость в `п. Рублево` и самая дешевая недвижимость в `г. Зеленоград`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно добавить больше критериев - агрегирующих функций. Например, минимальное и максимальное значения. Для этого добавляем в функцию `.agg` список функций `.agg([\"mean\", \"min\", \"max\"])`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"geo_block_0\").agg([\"mean\", \"min\", \"max\", len])[\"price_num\"].sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сводная таблица (анг. `pivot table`)\n",
    "\n",
    "Выше мы использовали функцию `groupby`, но есть возможность быстрее достигать некоторые результаты, при помощи сводных таблиц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df, index=[\"geo_block_0\"], values=[\"price_num\"], aggfunc=[\"mean\", \"min\", \"max\", len] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Статистические функции\n",
    "- `.min()`\n",
    "- `.max()`\n",
    "- `.mean()`\n",
    "- `.median()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Когда у нас список значений, то можно найти минимальные и максимальные значения в этом списке. Например, самая дешевая недвижимость (минимальное значение) и самая дорогая недвижимость (максимальное значение)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price_num\"].min(), df[\"price_num\"].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из наших данных получается, что самая дешевая недвижимость - это 1 млн. рублей, а самая дорогая - это более 3000 млн рублей (т.е. более 3 млрд. рублей)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень часто, анализируя данные, мы хотим как-то их \"уменьшить\" до одного числа, чтобы легче было сравнивать. Особенно часто прибегают к \"среднему значению\". Кстати, стоит заметить что существуют разные средние значения, но по умолчанию (если не уточняется) имеется в виду - [среднее арифметическое значение](https://ru.wikipedia.org/wiki/%D0%A1%D1%80%D0%B5%D0%B4%D0%BD%D0%B5%D0%B5_%D0%B0%D1%80%D0%B8%D1%84%D0%BC%D0%B5%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5).\n",
    "\n",
    "Пример - 5 значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = [1, 4, 2, 3, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сумма получается: 1 + 4 + 2 + 3 + 2 = 12.\n",
    "Всего элементов (чисел) - 5 штук\n",
    "\n",
    "Среднее будет: 12/5 = 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([1, 4, 2, 3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну хорошо, теперь можно заметить, что в среднем может быть очень большой изъян (чувствительность) на одно большое число. Предположим, что мы говорим о зарплате в компании.\n",
    "\n",
    "\n",
    "9 человек в этой компании зарабатывают - `$100` и один человек зарабатывает `$10 000`.  Какая будет средняя зарплата?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([100] * 9 + [10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что средняя зарплата больше тысячи долларов в этой компании. Знакомая история?\n",
    "\n",
    "\n",
    "\"средняя температура по больнице\" - это анекдот, который высмеивает ту же самую проблему.\n",
    "\n",
    "```\n",
    "— Какова средняя температура больных в энской больнице?\n",
    "— 36,6 °С, включая гнойное и морг!\n",
    "```\n",
    "«Один бьётся в горячке, другой остывает в морге, а средняя температура по больнице 36,6 °C.» (c)\n",
    "\n",
    "\n",
    "Медиана - частично решает выше перечисленные проблемы, так как работает иначе. Три этапа.\n",
    "1. Сортировка всех значений\n",
    "2. Поиск середины\n",
    "3. Элемент (или среднее пары, сейчас эти нюансы не так важны) и является медианой.\n",
    "\n",
    "\n",
    "Например с зарплатой.\n",
    "1. Сортируем зарплату, получается, что первые 9 элементов по 100 и последний 10 000.\n",
    "2. Так как кол-во элементов четное, то берем пару посередине (т.е. пятый и шестой элемент) \n",
    "3. Находим среднее `(100 + 100) / 2` получается 100\n",
    "\n",
    "Медиана в случае зарплаты получается 100. Как это интерпретировать - это как минимум у половины работников зарплата $100  или меньше (и наоборот)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median([100] * 9 + [10000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давай теперь применим эти знания для цен на недвижимость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price_num\"].mean(), df[\"price_num\"].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается среднее значение вышло более 17 млн. рублей. Но это прежде всего из-за того, что была недвжимость более 3 млд. рублей (это сильно завышает среднюю).\n",
    "\n",
    "Но в тоже время видно, что медиана 9.89 млн. рублей. Получается, что половина недвижимости стоит 9.89 млн рублей, либо меньше (ну и другая половина больше)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Визуализация\n",
    "- `.hist()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотреть на данные не только в виде таблички, но также и визуально. Сейчас познакомимся с [гистограммой](https://ru.wikipedia.org/wiki/%D0%93%D0%B8%D1%81%D1%82%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0).\n",
    "\n",
    "Посмотрим на то, как выглядит распределение цен на недвижимость."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"price_num\"].hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного \"искажается картина\" из-за того, что есть очень дорогая недвижимость (более 3 млрд. рублей). Есть разные способы, как бороться с \"отстающими значениями\" (анг. `outliers`). Один из самых простых - это \"пропустить\" через логарифм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(df[\"price_num\"]).hist(bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что большая часть недвижимости находится около 1. В данном случае 1 - это значит 10 млн. рублей.\n",
    "Значение 1.5 - это около 30 млн рублей. А почему столько? 10 в степени 1.5. В Python в степень можно возвести, используя оператор `**`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10**1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В случае `log10` можно легко интерпретировать так:\n",
    "- `log10( 1 )` => 0\n",
    "- `log10( 10 )` => 1\n",
    "- `log10( 100 )` => 2\n",
    "- `log10( 1000 )` => 3\n",
    "\n",
    "Обрати внимание, что это \"показывает\" количество нулей (это, конечно, упрощенная интерпретация)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Другие функции\n",
    "- `.qcut()` \n",
    "- `.unique()`\n",
    "- `.nunique()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иногда полезно создать \"корзинки\" и объединить некоторые значения, например, цены на недвижимость можно разделить на пять интервалов, от очень дешевой до очень дорогой. Для этого можно воспользоваться функцией `pd.qcut()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(df[\"price_num\"], 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кстати, можно теперь еще применить `.value_counts()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.qcut(df[\"price_num\"], 5).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что функция `.qcut()` пробовала равномерно распределить значение в этих 5 корзинках. Кстати, давай посмотрим, какие значения в этих корзинках:\n",
    "- `(1.039, 6.65]` - до 6млн. рублей самая дешевая недвижимость\n",
    "- `(6.65, 8.7]` - дешевая\n",
    "- `(8.7, 11.498]` - средняя\n",
    "- `(11.498, 17.68]` - дорогая\n",
    "- `(17.68, 3000.0]` - более 17 млн. рублей можно назвать очень дорогая"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И напоследок еще стоит рассмотреть две функции: `.unique()`  и `.nunique()`. Первая возвращает список уникальных значений, а вторая - количество уникальных значений (функция `.nunique()` особенно полезна тогда, когда мы не знаем, сколько уникальных значений и если их очень много, то предоставляя их, наш браузер может \"зависнуть\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"geo_block_0\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что в столбце `geo_block_0` у нас 9 значений - это не так уж много. Поэтому, можно их все посмотреть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"geo_block_0\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
